{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('http://120.78.95.32/j_n_contents.js')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('http://120.78.95.32/j_n_contents.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"toc\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(MLP,self).__init__(**kwargs)\n",
    "        self.hidden=nn.Linear(784,256)\n",
    "        self.act=nn.ReLU()\n",
    "        self.output=nn.Linear(256,10)\n",
    "    def forward(self,x):\n",
    "        a=self.act(self.hidden(x))\n",
    "        return self.output(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (act): ReLU()\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1299,  0.0159,  0.0638, -0.0603,  0.0092,  0.1026,  0.2844, -0.0253,\n",
       "          0.0915,  0.0495],\n",
       "        [-0.0021,  0.0007,  0.2268, -0.0478, -0.0319,  0.0082,  0.2326, -0.0517,\n",
       "          0.0093, -0.0225]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand(2,784)\n",
    "net=MLP()\n",
    "print(net)\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(*args):\n",
    "    for i in range(len(args)):\n",
    "        print(args[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yfu\n",
      "656576\n",
      "jyfk\n"
     ]
    }
   ],
   "source": [
    "test(\"yfu\",656576,\"jyfk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mysequential(nn.Module):\n",
    "    from collections import OrderedDict\n",
    "    def __init__(self,*args):\n",
    "        super(mysequential,self).__init__()\n",
    "        if len(args)==1 and isinstance(args[0],OrderDict):\n",
    "            for key,module in args[0].items():\n",
    "                self.add_module(key,module)\n",
    "        else:\n",
    "            for idx,module in enumerate(args):\n",
    "                self.add_module(str(idx),module)\n",
    "    def forward(self,input):\n",
    "        for module in self._modules.values():\n",
    "            input=module(input)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mysequential(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0412,  0.1308,  0.1828,  0.0573, -0.0449, -0.2617, -0.1807, -0.1659,\n",
       "          0.0012, -0.0337],\n",
       "        [ 0.0439,  0.0725, -0.0023,  0.0685,  0.0180, -0.0558, -0.0221, -0.1046,\n",
       "          0.1255,  0.0724]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=mysequential(\n",
    "    nn.Linear(784,256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,10)\n",
    ")\n",
    "print(net)\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=10, bias=True)\n",
      "ModuleDict(\n",
      "  (act): ReLU()\n",
      "  (linear): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net=nn.ModuleDict({\n",
    "    'linear':nn.Linear(784,256),\n",
    "    'act':nn.ReLU()\n",
    "})\n",
    "net['output']=nn.Linear(256,10)\n",
    "print(net['linear'])\n",
    "print(net.output)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fancymlp(nn.Module):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(fancymlp,self).__init__(**kwargs)\n",
    "        self.rand_weight=torch.rand((20,20),requires_grad=False)\n",
    "        self.linear=nn.Linear(20,20)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.linear(x)\n",
    "        x=nn.functional.relu(torch.mm(x,self.rand_weight.data)+1)\n",
    "        #这里两个全链接层共享参数\n",
    "        x=self.linear(x)\n",
    "        while x.norm().item()>1:\n",
    "            x/=2\n",
    "        if x.norm().item()<0.8:\n",
    "            x*=10\n",
    "        return x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fancymlp(\n",
      "  (linear): Linear(in_features=20, out_features=20, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-2.4397, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand(2,20)\n",
    "net=fancymlp()\n",
    "print(net)\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): nestmlp(\n",
      "    (net): Sequential(\n",
      "      (0): Linear(in_features=40, out_features=30, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=30, out_features=20, bias=True)\n",
      "  (2): fancymlp(\n",
      "    (linear): Linear(in_features=20, out_features=20, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-4.3859, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class nestmlp(nn.Module):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(nestmlp,self).__init__(**kwargs)\n",
    "        self.net=nn.Sequential(nn.Linear(40,30),nn.ReLU())\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "net=nn.Sequential(nestmlp(),nn.Linear(30,20),fancymlp())\n",
    "x=torch.rand(2,40)\n",
    "print(net)\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "net=nn.Sequential(nn.Linear(4,3),nn.ReLU(),nn.Linear(3,1))\n",
    "print(net)\n",
    "x=torch.rand(2,4)\n",
    "y=net(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n"
     ]
    }
   ],
   "source": [
    "print(type(net.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=net.named_parameters().__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.weight', Parameter containing:\n",
       " tensor([[ 0.3513,  0.4870,  0.3607,  0.4544],\n",
       "         [-0.2033, -0.3829, -0.2669,  0.2253],\n",
       "         [-0.2856,  0.1092,  0.2670,  0.0864]], requires_grad=True))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight torch.Size([3, 4])\n",
      "0.bias torch.Size([3])\n",
      "2.weight torch.Size([1, 3])\n",
      "2.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for n,p in net.named_parameters():\n",
    "    print(n,p.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight torch.Size([3, 4]) <class 'torch.nn.parameter.Parameter'>\n",
      "bias torch.Size([3]) <class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "for n,p in net[0].named_parameters():\n",
    "    print(n,p.size(),type(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight1\n"
     ]
    }
   ],
   "source": [
    "class mymodel(nn.Module):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(mymodel,self).__init__(**kwargs)\n",
    "        self.weight1=nn.Parameter(torch.rand(20,20))\n",
    "        self.weight2=torch.rand(20,20)\n",
    "    def forward(self,x):\n",
    "        pass\n",
    "n=mymodel()\n",
    "for n,p in n.named_parameters():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3513,  0.4870,  0.3607,  0.4544],\n",
      "        [-0.2033, -0.3829, -0.2669,  0.2253],\n",
      "        [-0.2856,  0.1092,  0.2670,  0.0864]])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "weight_0=list(net[0].parameters())[0]\n",
    "print(weight_0.data)\n",
    "print(weight_0.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0827, 0.0830, 0.0597, 0.1073],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(weight_0.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight tensor([[-0.0010, -0.0134,  0.0020, -0.0034],\n",
      "        [-0.0066,  0.0014, -0.0066, -0.0131],\n",
      "        [ 0.0188,  0.0048,  0.0101,  0.0055]])\n",
      "0.bias tensor([-0.0008, -0.0005, -0.0140])\n",
      "2.weight tensor([[-0.0072,  0.0009, -0.0060]])\n",
      "2.bias tensor([-0.0035])\n"
     ]
    }
   ],
   "source": [
    "for n,p in net.named_parameters():\n",
    "    init.normal_(p,mean=0,std=0.01)\n",
    "    print(n,p.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.bias tensor([0., 0., 0.])\n",
      "2.bias tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "for n,p in net.named_parameters():\n",
    "    if 'bias' in n:\n",
    "        init.constant_(p,val=0)\n",
    "        print(n,p.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_(tensor,mean=0,std=1):\n",
    "    with torch.no_grad():\n",
    "        return tensor.normal_(mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight tensor([[-8.0790,  0.0000, -0.0000, -0.0000],\n",
      "        [ 0.0000,  5.4508, -0.0000,  8.7420],\n",
      "        [ 0.0000, -0.0000,  0.0000,  0.0000]]) Parameter containing:\n",
      "tensor([[-8.0790,  0.0000, -0.0000, -0.0000],\n",
      "        [ 0.0000,  5.4508, -0.0000,  8.7420],\n",
      "        [ 0.0000, -0.0000,  0.0000,  0.0000]], requires_grad=True)\n",
      "2.weight tensor([[-0.0000, -6.7450, -0.0000]]) Parameter containing:\n",
      "tensor([[-0.0000, -6.7450, -0.0000]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "def init_weight(tensor):\n",
    "    with torch.no_grad():\n",
    "        tensor.uniform_(-10,10)\n",
    "        tensor*=(tensor.abs()>=5).float()\n",
    "for n,p in net.named_parameters():\n",
    "    if 'weight' in n:\n",
    "        init_weight(p)\n",
    "        print(n,p.data,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=1, out_features=1, bias=False)\n",
      "  (1): Linear(in_features=1, out_features=1, bias=False)\n",
      ")\n",
      "0.weight tensor([[3.]])\n"
     ]
    }
   ],
   "source": [
    "linear=nn.Linear(1,1,bias=False)\n",
    "net=nn.Sequential(linear,linear)\n",
    "print(net)\n",
    "for n,p in net.named_parameters():\n",
    "    init.constant_(p,val=3)\n",
    "    print(n,p.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(net[0])==id(net[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9., grad_fn=<SumBackward0>)\n",
      "tensor([[6.]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(1,1)\n",
    "y=net(x).sum()\n",
    "print(y)\n",
    "y.backward()\n",
    "print(net[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "class centerlayer(nn.Module):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(centerlayer,self).__init__(**kwargs)\n",
    "    def forward(self,x):\n",
    "        return x-x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer=centerlayer()\n",
    "layer(torch.tensor([1,2,3,4,5],dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=nn.Sequential(nn.Linear(8,128),centerlayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.587935447692871e-09"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=net(torch.rand(4,8))\n",
    "y.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mydense(\n",
      "  (params): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (3): Parameter containing: [torch.FloatTensor of size 4x1]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class mydense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mydense,self).__init__()\n",
    "        self.params=nn.ParameterList([nn.Parameter(torch.randn(4,4)) for i in range(3)])\n",
    "        self.params.append(nn.Parameter(torch.randn(4,1)))\n",
    "    def forward(self,x):\n",
    "        for i in range(len(self.params)):\n",
    "            x=torch.mm(x,self.params[i])\n",
    "        return x\n",
    "nett=mydense()\n",
    "print(nett)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.7319]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(1,4)\n",
    "print(nett(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mydictdense(\n",
      "  (params): ParameterDict(\n",
      "      (linear1): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "      (linear2): Parameter containing: [torch.FloatTensor of size 4x1]\n",
      "      (linear3): Parameter containing: [torch.FloatTensor of size 4x2]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class mydictdense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mydictdense,self).__init__()\n",
    "        self.params=nn.ParameterDict(\n",
    "        {\n",
    "            'linear1':nn.Parameter(torch.randn(4,4)),\n",
    "            'linear2':nn.Parameter(torch.randn(4,1))\n",
    "        }\n",
    "        )\n",
    "        self.params.update({'linear3':nn.Parameter(torch.randn(4,2))})\n",
    "    def forward(self,x,choice='linear1'):\n",
    "        return torch.mm(x,self.params[choice])\n",
    "\n",
    "\n",
    "net=mydictdense()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0587, 4.7130, 1.1160, 1.9081]], grad_fn=<MmBackward>)\n",
      "tensor([[2.2800]], grad_fn=<MmBackward>)\n",
      "tensor([[-2.9252, -0.5998]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(1,4)\n",
    "print(net(x,'linear1'))\n",
    "print(net(x,'linear2'))\n",
    "print(net(x,'linear3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=nn.Sequential(mydictdense(),mydense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): mydictdense(\n",
      "    (params): ParameterDict(\n",
      "        (linear1): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "        (linear2): Parameter containing: [torch.FloatTensor of size 4x1]\n",
      "        (linear3): Parameter containing: [torch.FloatTensor of size 4x2]\n",
      "    )\n",
      "  )\n",
      "  (1): mydense(\n",
      "    (params): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 4x4]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 4x1]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "tensor([[-1.8665]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(net)\n",
    "print(net(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "x=torch.ones(3)\n",
    "torch.save(x,'x.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2=torch.load('x.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1., 1., 1.]), tensor([0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=torch.zeros(4)\n",
    "torch.save([x,y],'xy.pt')\n",
    "xy_list=torch.load('xy.pt')\n",
    "xy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([1., 1., 1.]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save({'x':x,'y':y},'xy_dict.pt')\n",
    "xy=torch.load('xy_dict.pt')\n",
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.weight', tensor([[-0.4716, -0.5011,  0.3597],\n",
       "                      [-0.0201,  0.4677,  0.3217]])),\n",
       "             ('hidden.bias', tensor([-0.4616,  0.4051])),\n",
       "             ('output.weight', tensor([[-0.0776, -0.1656]])),\n",
       "             ('output.bias', tensor([-0.0934]))])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mlp,self).__init__()\n",
    "        self.hidden=nn.Linear(3,2)\n",
    "        self.act=nn.ReLU()\n",
    "        self.output=nn.Linear(2,1)\n",
    "    def forward(self,x):\n",
    "        a=self.act(self.hidden(x))\n",
    "        return self.output(a)\n",
    "net=mlp()\n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {},\n",
       " 'param_groups': [{'lr': 0.001,\n",
       "   'momentum': 0.9,\n",
       "   'dampening': 0,\n",
       "   'weight_decay': 0,\n",
       "   'nesterov': False,\n",
       "   'params': [140429638476496,\n",
       "    140429638478728,\n",
       "    140429638477864,\n",
       "    140429638477648]}]}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer=torch.optim.SGD(net.parameters(),lr=0.001,momentum=0.9)\n",
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True],\n",
       "        [True]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn(2,3)\n",
    "y=net(x)\n",
    "torch.save(net.state_dict(),\"net.pt\")\n",
    "net2=mlp()\n",
    "net2.load_state_dict(torch.load(\"net.pt\"))\n",
    "y2=net2(x)\n",
    "y2==y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar  8 20:02:18 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 23%   25C    P8     8W / 250W |     10MiB / 11178MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:82:00.0 Off |                  N/A |\r\n",
      "| 23%   22C    P8     9W / 250W |     10MiB / 11178MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([1,2,3])\n",
    "x=x.to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=nn.Linear(3,1)\n",
    "list(net.parameters())[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(torch.device(\"cuda\"))\n",
    "list(net.parameters())[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand(2,3)\n",
    "x=x.to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0129],\n",
       "        [0.1841]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
