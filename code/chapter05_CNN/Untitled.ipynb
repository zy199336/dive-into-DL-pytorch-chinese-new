{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript(\"http://120.78.95.32/j_n_contents.js\")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript(\"http://120.78.95.32/j_n_contents.js\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"toc\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "def corr2d(x,k):\n",
    "    h,w=k.shape\n",
    "    y=torch.zeros((x.shape[0]-h+1,x.shape[1]-w+1))\n",
    "    for i in range(y.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            y[i,j]=(x[i:i+h,j:j+w]*k).sum()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([[0,1,2],[3,4,5],[6,7,8]])\n",
    "k=torch.tensor([[0,1],[2,3]])\n",
    "corr2d(x,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2d(nn.Module):\n",
    "    def __init__(self,kernel_size):\n",
    "        super(conv2d,self).__init__()\n",
    "        self.weight=nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias=nn.Parameter(torch.randn(1))\n",
    "    def forward(self,x):\n",
    "        return corr2d(x,self.weight)+self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.ones(6,8)\n",
    "x[:,2:6]=0\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=torch.tensor([[1,-1]],dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=corr2d(x,k)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5,loss 6.467115879058838\n",
      "step 10,loss 1.7793506383895874\n",
      "step 15,loss 0.4931490123271942\n",
      "step 20,loss 0.13707450032234192\n"
     ]
    }
   ],
   "source": [
    "conv=conv2d(kernel_size=(1,2))\n",
    "step=20\n",
    "lr=0.01\n",
    "for i in range(step):\n",
    "    y_hat=conv(x)\n",
    "    l=((y_hat-y)**2).sum()\n",
    "    l.backward()\n",
    "    \n",
    "    conv.weight.data-=lr*conv.weight.grad\n",
    "    conv.bias.data-=lr*conv.bias.grad\n",
    "    conv.weight.grad.fill_(0)\n",
    "    conv.bias.grad.fill_(0)\n",
    "    if (i+1)%5==0:\n",
    "        print(\"step {},loss {}\".format(i+1,l.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9079, -0.9041]])\n",
      "tensor([-0.0021])\n"
     ]
    }
   ],
   "source": [
    "print(conv.weight.data)\n",
    "print(conv.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 填充和步幅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "def comp_conv2d(conv2d,x):\n",
    "    x=x.view((1,1)+x.shape)\n",
    "    y=conv2d(x)\n",
    "    return y.view(y.shape[2:])\n",
    "\n",
    "conv2d=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,padding=1)\n",
    "x=torch.rand(8,8)\n",
    "comp_conv2d(conv2d,x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d=nn.Conv2d(in_channels=1,out_channels=1,kernel_size=(5,3),padding=(2,1))\n",
    "comp_conv2d(conv2d,x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d=nn.Conv2d(1,1,kernel_size=3,padding=1,stride=2)\n",
    "comp_conv2d(conv2d,x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 多输入输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import d2lzh_pytorch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(x,k):\n",
    "    res=d2l.corr2d(x[0,:,:],k[0,:,:])\n",
    "    for i in range(1,x.shape[0]):\n",
    "        res+=d2l.corr2d(x[i,:,:],k[i,:,:])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([[[0,1,2],[3,4,5],[6,7,8]],[[1,2,3],[4,5,6],[7,8,9]]])\n",
    "k=torch.tensor([[[0,1],[2,3]],[[1,2],[3,4]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 3]), torch.Size([2, 2, 2]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in(x,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(x,k):\n",
    "    return torch.stack([corr2d_multi_in(x,a) for a in k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=torch.stack([k,k+1,k+2])\n",
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(x,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_11(x,k):\n",
    "    c_i,h,w=x.shape\n",
    "    c_o=k.shape[0]\n",
    "    x=x.view(c_i,h*w)\n",
    "    k=k.view(c_o,c_i)\n",
    "    y=torch.mm(k,x)\n",
    "    return y.view(c_o,h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand(3,3,3)\n",
    "k=torch.rand(2,3,1,1)\n",
    "y1=corr2d_multi_in_out_11(x,k)\n",
    "y2=corr2d_multi_in_out(x,k)\n",
    "(y1-y2).norm().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.4 池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=nn.MaxPool2d(kernel_size=2,stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([[[0,1,2],[3,4,5],[6,7,8]]],dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 5.],\n",
       "         [7., 8.]]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=nn.AvgPool2d(kernel_size=2,stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 3.],\n",
       "         [5., 6.]]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [7., 8.]]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=nn.MaxPool2d((2,4),padding=(1,2),stride=(2,3))\n",
    "c(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.5 LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import d2lzh_pytorch as d2l\n",
    "device=torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        self.conv=nn.Sequential(\n",
    "            nn.Conv2d(1,6,5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(6,16,5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Linear(16*4*4,120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120,84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84,10)\n",
    "        )\n",
    "    def forward(self,img):\n",
    "        a=self.conv(img)\n",
    "        output=self.fc(a.view(img.shape[0],-1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): Sigmoid()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=120, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net=LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "train_iter,test_iter=d2l.load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 1.9338, train acc 0.282, test acc 0.575, time 2.6 sec\n",
      "epoch 2, loss 0.4817, train acc 0.632, test acc 0.675, time 2.5 sec\n",
      "epoch 3, loss 0.2603, train acc 0.713, test acc 0.724, time 2.5 sec\n",
      "epoch 4, loss 0.1737, train acc 0.739, test acc 0.742, time 2.6 sec\n",
      "epoch 5, loss 0.1277, train acc 0.755, test acc 0.755, time 2.6 sec\n"
     ]
    }
   ],
   "source": [
    "lr,num_epochs=0.001,5\n",
    "optimizer=torch.optim.Adam(net.parameters(),lr=lr)\n",
    "\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.6 AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import torchvision\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import d2lzh_pytorch as d2l\n",
    "device=torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet,self).__init__()\n",
    "        self.conv=nn.Sequential(\n",
    "            nn.Conv2d(1,96,11,4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3,2),\n",
    "            nn.Conv2d(96,256,5,1,2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3,2),\n",
    "            nn.Conv2d(256,384,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384,384,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384,256,3,1,1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3,2)\n",
    "        )\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Linear(256*5*5,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096,10)\n",
    "        \n",
    "        )\n",
    "    def forward(self,img):\n",
    "        a=self.conv(img)\n",
    "        return self.fc(a.view(img.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net=AlexNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "train_iter,test_iter=d2l.load_data_fashion_mnist(batch_size,resize=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.6425, train acc 0.755, test acc 0.846, time 33.9 sec\n",
      "epoch 2, loss 0.1767, train acc 0.868, test acc 0.881, time 34.6 sec\n",
      "epoch 3, loss 0.1008, train acc 0.887, test acc 0.891, time 34.7 sec\n",
      "epoch 4, loss 0.0692, train acc 0.898, test acc 0.893, time 34.7 sec\n",
      "epoch 5, loss 0.0500, train acc 0.907, test acc 0.902, time 34.4 sec\n"
     ]
    }
   ],
   "source": [
    "lr,num_epochs=0.001,5\n",
    "optimizer=torch.optim.Adam(net.parameters(),lr=lr)\n",
    "d2l.train_ch5(net,train_iter,test_iter,batch_size,optimizer,device,num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.7 VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import d2lzh_pytorch as d2l\n",
    "device=torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(num_convs,in_channels,out_channels):\n",
    "\n",
    "    blk=[]\n",
    "    for i in range(num_convs):\n",
    "        if i==0:\n",
    "            blk.append(nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1))\n",
    "        else:\n",
    "            blk.append(nn.Conv2d(out_channels,out_channels,kernel_size=3,padding=1))\n",
    "        blk.append(nn.ReLU())\n",
    "    blk.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "    b=nn.Sequential(*blk)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vgg_block(nn.Module):\n",
    "    def __init__(self,num_convs,fc_features,fc_hidden_units):\n",
    "        super(vgg_block,self).__init__()\n",
    "        \n",
    "        self.net=nn.Sequential()\n",
    "        for j ,(num,i,o) in enumerate(num_convs):\n",
    "            self.net.add_module('block_'+str(j+1),block(num,i,o))\n",
    "        self.net.add_module(\"fc\",nn.Sequential(\n",
    "            d2l.FlattenLayer(),\n",
    "            nn.Linear(fc_features,fc_hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(fc_hidden_units,fc_hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(fc_hidden_units,10)\n",
    "        ))\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self,img):\n",
    "        return self.net(img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=((1,1,64),(1,64,128),(2,128,256),(2,256,512),(2,512,512))\n",
    "fc_features=512*7*7\n",
    "fc_hidden_units=4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=vgg_block(conv,fc_features,fc_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg_block(\n",
      "  (net): Sequential(\n",
      "    (block_1): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (block_2): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (block_3): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (block_4): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (block_5): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): FlattenLayer()\n",
      "      (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.5, inplace=False)\n",
      "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Dropout(p=0.5, inplace=False)\n",
      "      (7): Linear(in_features=4096, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_1 output shape:  torch.Size([1, 64, 112, 112])\n",
      "block_2 output shape:  torch.Size([1, 128, 56, 56])\n",
      "block_3 output shape:  torch.Size([1, 256, 28, 28])\n",
      "block_4 output shape:  torch.Size([1, 512, 14, 14])\n",
      "block_5 output shape:  torch.Size([1, 512, 7, 7])\n",
      "fc output shape:  torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(1,1,224,224)\n",
    "for n,b in net.named_children():\n",
    "    for t1,t2 in b.named_children():\n",
    "        x=t2(x)\n",
    "        print(t1,'output shape: ',x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio=8\n",
    "small_conv_arch = [(1, 1, 64//ratio), (1, 64//ratio, 128//ratio), (2, 128//ratio, 256//ratio),\n",
    "(2, 256//ratio, 512//ratio), (2, 512//ratio, 512//ratio)]\n",
    "net=vgg_block(small_conv_arch,fc_features//ratio,fc_hidden_units//ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.5973, train acc 0.777, test acc 0.873, time 36.7 sec\n",
      "epoch 2, loss 0.1652, train acc 0.879, test acc 0.895, time 36.9 sec\n",
      "epoch 3, loss 0.0946, train acc 0.898, test acc 0.895, time 36.8 sec\n",
      "epoch 4, loss 0.0628, train acc 0.910, test acc 0.914, time 36.9 sec\n",
      "epoch 5, loss 0.0460, train acc 0.916, test acc 0.916, time 36.9 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "train_iter,test_iter=d2l.load_data_fashion_mnist(batch_size,resize=224)\n",
    "lr,num_epochs=0.001,5\n",
    "optimizer=torch.optim.Adam(net.parameters(),lr=lr)\n",
    "net.to(torch.device(\"cuda\"))\n",
    "d2l.train_ch5(net,train_iter,test_iter,batch_size,optimizer,device,num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.8 NiN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import d2lzh_pytorch as d2l\n",
    "device=torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nin_block(in_channels,out_channels,kernel_size,stride,padding):\n",
    "    blk=nn.Sequential(\n",
    "        nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(out_channels,out_channels,kernel_size=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(out_channels,out_channels,kernel_size=1),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "    return blk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nin(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(nin,self).__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nin_block(1,96,11,4,0),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            nin_block(96,256,5,1,2),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            nin_block(256,384,3,1,1),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            nn.Dropout(0.5),\n",
    "            nin_block(384,10,3,1,1),\n",
    "            d2l.GlobalAvgPool2d(),\n",
    "            d2l.FlattenLayer()\n",
    "        )\n",
    "    def forward(self,img):\n",
    "        return self.net(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nin(\n",
      "  (net): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): Sequential(\n",
      "      (0): Conv2d(384, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(10, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (8): GlobalAvgPool2d()\n",
      "    (9): FlattenLayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net=nin()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 output shape:  torch.Size([1, 96, 54, 54])\n",
      "1 output shape:  torch.Size([1, 96, 26, 26])\n",
      "2 output shape:  torch.Size([1, 256, 26, 26])\n",
      "3 output shape:  torch.Size([1, 256, 12, 12])\n",
      "4 output shape:  torch.Size([1, 384, 12, 12])\n",
      "5 output shape:  torch.Size([1, 384, 5, 5])\n",
      "6 output shape:  torch.Size([1, 384, 5, 5])\n",
      "7 output shape:  torch.Size([1, 10, 5, 5])\n",
      "8 output shape:  torch.Size([1, 10, 1, 1])\n",
      "9 output shape:  torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(1,1,224,224)\n",
    "x.to(torch.device(\"cuda\"))\n",
    "for n,b in net.named_children():\n",
    "    for t1,t2 in b.named_children():\n",
    "        x=t2(x)\n",
    "        print(t1,'output shape: ',x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 1.3338, train acc 0.525, test acc 0.765, time 41.7 sec\n",
      "epoch 2, loss 0.2932, train acc 0.788, test acc 0.810, time 41.9 sec\n",
      "epoch 3, loss 0.1671, train acc 0.814, test acc 0.816, time 42.0 sec\n",
      "epoch 4, loss 0.1146, train acc 0.829, test acc 0.831, time 42.1 sec\n",
      "epoch 5, loss 0.0862, train acc 0.839, test acc 0.838, time 42.1 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "train_iter,test_iter=d2l.load_data_fashion_mnist(batch_size,resize=224)\n",
    "lr,num_epochs=0.002,5\n",
    "optimizer=torch.optim.Adam(net.parameters(),lr=lr)\n",
    "d2l.train_ch5(net,train_iter,test_iter,batch_size,optimizer,device,num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.9 GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import d2lzh_pytorch as d2l\n",
    "device=torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(self,in_,c1,c2,c3,c4):\n",
    "        super(Inception,self).__init__()\n",
    "        self.p1_1=nn.Conv2d(in_,c1,kernel_size=1)\n",
    "        self.p2_1=nn.Conv2d(in_,c2[0],kernel_size=1)\n",
    "        self.p2_2=nn.Conv2d(c2[0],c2[1],kernel_size=3,padding=1)\n",
    "        self.p3_1=nn.Conv2d(in_,c3[0],kernel_size=1)\n",
    "        self.p3_2=nn.Conv2d(c3[0],c3[1],kernel_size=5,padding=2)\n",
    "        self.p4_1=nn.MaxPool2d(kernel_size=3,stride=1,padding=1)\n",
    "        self.p4_2=nn.Conv2d(in_,c4,kernel_size=1)\n",
    "        self.p1=nn.Sequential(\n",
    "            self.p1_1,\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.p2=nn.Sequential(\n",
    "            self.p2_1,\n",
    "            nn.ReLU(),\n",
    "            self.p2_2,\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.p3=nn.Sequential(\n",
    "            self.p3_1,\n",
    "            nn.ReLU(),\n",
    "            self.p3_2,\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.p4=nn.Sequential(\n",
    "            self.p4_1,\n",
    "            self.p4_2,\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        result1=self.p1(x)\n",
    "        result2=self.p2(x)\n",
    "        result3=self.p3(x)\n",
    "        result4=self.p4(x)\n",
    "        return torch.cat((result1,result2,result3,result4),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Googlenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Googlenet,self).__init__()\n",
    "        \n",
    "        self.b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "        \n",
    "        self.b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
    "        nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "        \n",
    "        self.b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),\n",
    "        Inception(256, 128, (128, 192), (32, 96), 64),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "        \n",
    "        self.b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "        Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "        Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "        Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "        Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "        \n",
    "        self.b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "        Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "        d2l.GlobalAvgPool2d())\n",
    "        \n",
    "        \n",
    "        #self.t=nn.Sequential(\n",
    "        #    self.b1, self.b2, self.b3, self.b4, self.b5,\n",
    "        #    d2l.FlattenLayer(), \n",
    "        #    nn.Linear(1024, 10))\n",
    "\n",
    "    def forward(self,img):\n",
    "        img=img.to(torch.device(\"cuda\"))\n",
    "        t = nn.Sequential(\n",
    "             self.b1, self.b2, self.b3, self.b4, self.b5,\n",
    "             d2l.FlattenLayer(), \n",
    "             nn.Linear(1024, 10)\n",
    "        )\n",
    "        t=t.to(torch.device(\"cuda\"))\n",
    "        #x = self.b1(img)\n",
    "        #x = self.b2(x)\n",
    "        #x = self.b3(x)\n",
    "        #x = self.b4(x)\n",
    "        #x = self.b5(x)\n",
    "        return t(img)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Googlenet(\n",
      "  (b1): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (b2): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (b3): Sequential(\n",
      "    (0): Inception(\n",
      "      (p1_1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p1): Sequential(\n",
      "        (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (p2): Sequential(\n",
      "        (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (p3): Sequential(\n",
      "        (0): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (p4): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (1): Inception(\n",
      "      (p1_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p1): Sequential(\n",
      "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (p2): Sequential(\n",
      "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (p3): Sequential(\n",
      "        (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (p4): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (b4): Sequential(\n",
      "    (0): Inception(\n",
      "      (p1_1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p1): Sequential(\n",
      "        (0): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (p2): Sequential(\n",
      "        (0): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (p3): Sequential(\n",
      "        (0): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (p4): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (1): Inception(\n",
      "      (p1_1): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p1): Sequential(\n",
      "        (0): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (p2): Sequential(\n",
      "        (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (p3): Sequential(\n",
      "        (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (p4): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (2): Inception(\n",
      "      (p1_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p1): Sequential(\n",
      "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (p2): Sequential(\n",
      "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (p3): Sequential(\n",
      "        (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (p4): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (3): Inception(\n",
      "      (p1_1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p1): Sequential(\n",
      "        (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (p2): Sequential(\n",
      "        (0): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (p3): Sequential(\n",
      "        (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (p4): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (4): Inception(\n",
      "      (p1_1): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p1): Sequential(\n",
      "        (0): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (p2): Sequential(\n",
      "        (0): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (p3): Sequential(\n",
      "        (0): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (p4): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (b5): Sequential(\n",
      "    (0): Inception(\n",
      "      (p1_1): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p1): Sequential(\n",
      "        (0): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (p2): Sequential(\n",
      "        (0): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (p3): Sequential(\n",
      "        (0): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (p4): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (1): Inception(\n",
      "      (p1_1): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_1): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p2_2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (p3_1): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p3_2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (p4_2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (p1): Sequential(\n",
      "        (0): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (p2): Sequential(\n",
      "        (0): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (p3): Sequential(\n",
      "        (0): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "      (p4): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (2): GlobalAvgPool2d()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net=Googlenet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      ")\n",
      "torch.Size([1, 64, 24, 24])\n",
      "Sequential(\n",
      "  (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (1): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      ")\n",
      "torch.Size([1, 192, 12, 12])\n",
      "Sequential(\n",
      "  (0): Inception(\n",
      "    (p1_1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_2): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (p3_1): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p3_2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (p4_2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p1): Sequential(\n",
      "      (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Inception(\n",
      "    (p1_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (p3_1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p3_2): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (p4_2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p1): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      ")\n",
      "torch.Size([1, 480, 6, 6])\n",
      "Sequential(\n",
      "  (0): Inception(\n",
      "    (p1_1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_1): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_2): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (p3_1): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p3_2): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (p4_2): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p1): Sequential(\n",
      "      (0): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Inception(\n",
      "    (p1_1): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_2): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (p3_1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p3_2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p1): Sequential(\n",
      "      (0): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (2): Inception(\n",
      "    (p1_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (p3_1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p3_2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p1): Sequential(\n",
      "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (3): Inception(\n",
      "    (p1_1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_1): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_2): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (p3_1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p3_2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p1): Sequential(\n",
      "      (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (4): Inception(\n",
      "    (p1_1): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_1): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (p3_1): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p3_2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (p4_2): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p1): Sequential(\n",
      "      (0): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      ")\n",
      "torch.Size([1, 832, 3, 3])\n",
      "Sequential(\n",
      "  (0): Inception(\n",
      "    (p1_1): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_1): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (p3_1): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p3_2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (p4_2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p1): Sequential(\n",
      "      (0): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Inception(\n",
      "    (p1_1): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_1): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p2_2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (p3_1): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p3_2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (p4_2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p1): Sequential(\n",
      "      (0): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (p2): Sequential(\n",
      "      (0): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (p3): Sequential(\n",
      "      (0): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (p4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (2): GlobalAvgPool2d()\n",
      ")\n",
      "torch.Size([1, 1024, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 1, 96, 96)\n",
    "for a in net.children():\n",
    "    print(a)\n",
    "    x=a(x)\n",
    "\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-680bf13360bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-190fe2514ba2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m#x = self.b4(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m#x = self.b5(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    338\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    339\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 340\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 1, 96, 96)\n",
    "x=x.to(torch.device(\"cuda\"))\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 2.3029, train acc 0.101, test acc 0.102, time 32.6 sec\n",
      "epoch 2, loss 1.1514, train acc 0.102, test acc 0.100, time 33.0 sec\n",
      "epoch 3, loss 0.7676, train acc 0.099, test acc 0.103, time 32.7 sec\n",
      "epoch 4, loss 0.5757, train acc 0.100, test acc 0.097, time 33.8 sec\n",
      "epoch 5, loss 0.4606, train acc 0.100, test acc 0.100, time 33.2 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1\n",
      "b2\n",
      "b3\n",
      "b4\n",
      "b5\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "for i,j in net.named_children():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.10 批量归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=nn.Sequential(\n",
    "    nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size\n",
    "    nn.BatchNorm2d(6),\n",
    "    nn.Sigmoid(),\n",
    "    nn.MaxPool2d(2, 2), # kernel_size, stride\n",
    "    nn.Conv2d(6, 16, 5),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.Sigmoid(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    d2l.FlattenLayer(),\n",
    "    nn.Linear(16*4*4, 120),\n",
    "    nn.BatchNorm1d(120),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(120, 84),\n",
    "    nn.BatchNorm1d(84),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(84, 10)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.9693, train acc 0.793, test acc 0.837, time 3.0 sec\n",
      "epoch 2, loss 0.2279, train acc 0.863, test acc 0.832, time 3.0 sec\n",
      "epoch 3, loss 0.1231, train acc 0.876, test acc 0.870, time 2.9 sec\n",
      "epoch 4, loss 0.0829, train acc 0.886, test acc 0.871, time 2.8 sec\n",
      "epoch 5, loss 0.0619, train acc 0.892, test acc 0.850, time 2.9 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.11 ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import d2lzh_pytorch as d2l\n",
    "device=torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "class residual(nn.Module):\n",
    "    def __init__(self,in_,out_,use11=False,stride=1):\n",
    "        super(residual,self).__init__()\n",
    "        self.c1=nn.Conv2d(in_,out_,kernel_size=3,padding=1,stride=stride)\n",
    "        self.c2=nn.Conv2d(out_,out_,kernel_size=3,padding=1)\n",
    "        self.b1=nn.BatchNorm2d(out_)\n",
    "        self.b2=nn.BatchNorm2d(out_)\n",
    "        self.net1=nn.Sequential(\n",
    "            self.c1,\n",
    "            self.b1,\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        if use11:\n",
    "            self.net2=nn.Conv2d(in_, out_, kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.net2=None\n",
    "\n",
    "    def forward(self,img):\n",
    "        r1=self.net1(img)\n",
    "        if self.net2:\n",
    "            r2=self.net2(img)\n",
    "        else:\n",
    "            r2=img\n",
    "        return F.relu(r2+r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 6, 6])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk=residual(3,3)\n",
    "x=torch.rand((4,3,6,6))\n",
    "blk(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 3, 3])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk=residual(3,6,True,stride=2)\n",
    "blk(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(in_,out_,num_,first_=False):\n",
    "    if first_:\n",
    "        assert in_ == out_\n",
    "    blk=[]\n",
    "    for i in range(num_):\n",
    "        if i==0 and not first_:\n",
    "            blk.append(residual(in_,out_,True,2))\n",
    "        else:\n",
    "            blk.append(residual(out_,out_))\n",
    "    return nn.Sequential(*blk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "net= nn.Sequential(\n",
    "    nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "    resnet_block(64, 64, 2, first_=True),\n",
    "    resnet_block(64,128,2),\n",
    "    resnet_block(128,256,2),\n",
    "    resnet_block(256,512,2),\n",
    "    d2l.GlobalAvgPool2d(),\n",
    "    d2l.FlattenLayer(),\n",
    "    nn.Linear(512,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 output shape  torch.Size([1, 64, 112, 112])\n",
      "1 output shape  torch.Size([1, 64, 112, 112])\n",
      "2 output shape  torch.Size([1, 64, 112, 112])\n",
      "3 output shape  torch.Size([1, 64, 56, 56])\n",
      "4 output shape  torch.Size([1, 64, 56, 56])\n",
      "5 output shape  torch.Size([1, 128, 28, 28])\n",
      "6 output shape  torch.Size([1, 256, 14, 14])\n",
      "7 output shape  torch.Size([1, 512, 7, 7])\n",
      "8 output shape  torch.Size([1, 512, 1, 1])\n",
      "9 output shape  torch.Size([1, 512])\n",
      "10 output shape  torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand((1,1,224,224))\n",
    "for n,l in net.named_children():\n",
    "    x=l(x)\n",
    "    print(n,\"output shape \",x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.3562, train acc 0.869, test acc 0.894, time 18.4 sec\n",
      "epoch 2, loss 0.1133, train acc 0.916, test acc 0.881, time 18.5 sec\n",
      "epoch 3, loss 0.0606, train acc 0.934, test acc 0.919, time 18.5 sec\n",
      "epoch 4, loss 0.0385, train acc 0.943, test acc 0.920, time 18.6 sec\n",
      "epoch 5, loss 0.0258, train acc 0.953, test acc 0.920, time 18.6 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.12 DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(in_,out_):\n",
    "    r=nn.Sequential(\n",
    "        nn.BatchNorm2d(in_),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_,out_,kernel_size=3,padding=1)\n",
    "    )\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "class denseblock(nn.Module):\n",
    "    def __init__(self,num_,in_,out_):\n",
    "        super(denseblock,self).__init__()\n",
    "        net=[]\n",
    "        for i in range(num_):\n",
    "            in_c=in_+i*out_\n",
    "            net.append(block(in_c,out_))\n",
    "        self.nett=nn.ModuleList(net)\n",
    "        self.out_channels=in_+num_*out_\n",
    "    def forward(self,x):\n",
    "        for blk in self.nett:\n",
    "            y=blk(x)\n",
    "            x=torch.cat((x,y),dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 23, 8, 8])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk=denseblock(2,3,10)\n",
    "x=torch.rand(4,3,8,8)\n",
    "y=blk(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_block(in_,out_):\n",
    "    blk=nn.Sequential(\n",
    "        nn.BatchNorm2d(in_),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_,out_,kernel_size=1),\n",
    "        nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "    )\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 4, 4])"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=transition_block(23,10)\n",
    "b(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_,growth_=64,32\n",
    "num_c=[4,4,4,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels, growth_rate = 64, 32\n",
    " # num_channels为当前的通道数\n",
    "num_convs_in_dense_blocks = [4, 4, 4, 4]\n",
    "for i, num_convs in enumerate(num_convs_in_dense_blocks):\n",
    "    DB = denseblock(num_convs, num_channels, growth_rate)\n",
    "    net.add_module(\"DenseBlosk_%d\" % i, DB)\n",
    "    # 上一个稠密块的输出通道数\n",
    "    num_channels = DB.out_channels\n",
    "    # 在稠密块之间加入通道数减半的过渡层\n",
    "    if i != len(num_convs_in_dense_blocks) - 1:\n",
    "        net.add_module(\"transition_block_%d\" % i, transition_block(num_channels, num_channels //\n",
    "        2))\n",
    "        num_channels = num_channels // 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.add_module(\"BN\", nn.BatchNorm2d(num_channels))\n",
    "net.add_module(\"relu\", nn.ReLU())\n",
    "net.add_module(\"global_avg_pool\", d2l.GlobalAvgPool2d())\n",
    "net.add_module(\"fc\", nn.Sequential(d2l.FlattenLayer(), nn.Linear(num_channels, 10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  output shape:\t torch.Size([1, 64, 48, 48])\n",
      "1  output shape:\t torch.Size([1, 64, 48, 48])\n",
      "2  output shape:\t torch.Size([1, 64, 48, 48])\n",
      "3  output shape:\t torch.Size([1, 64, 24, 24])\n",
      "DenseBlosk_0  output shape:\t torch.Size([1, 192, 24, 24])\n",
      "transition_block_0  output shape:\t torch.Size([1, 96, 12, 12])\n",
      "DenseBlosk_1  output shape:\t torch.Size([1, 224, 12, 12])\n",
      "transition_block_1  output shape:\t torch.Size([1, 112, 6, 6])\n",
      "DenseBlosk_2  output shape:\t torch.Size([1, 240, 6, 6])\n",
      "transition_block_2  output shape:\t torch.Size([1, 120, 3, 3])\n",
      "DenseBlosk_3  output shape:\t torch.Size([1, 248, 3, 3])\n",
      "BN  output shape:\t torch.Size([1, 248, 3, 3])\n",
      "relu  output shape:\t torch.Size([1, 248, 3, 3])\n",
      "global_avg_pool  output shape:\t torch.Size([1, 248, 1, 1])\n",
      "fc  output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((1, 1, 96, 96))\n",
    "for name, layer in net.named_children():\n",
    "    X = layer(X)\n",
    "    print(name, ' output shape:\\t', X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.4580, train acc 0.838, test acc 0.830, time 21.5 sec\n",
      "epoch 2, loss 0.1351, train acc 0.902, test acc 0.849, time 21.5 sec\n",
      "epoch 3, loss 0.0772, train acc 0.916, test acc 0.893, time 21.6 sec\n",
      "epoch 4, loss 0.0519, train acc 0.925, test acc 0.903, time 21.7 sec\n",
      "epoch 5, loss 0.0382, train acc 0.930, test acc 0.914, time 21.6 sec\n"
     ]
    }
   ],
   "source": [
    "size = 256\n",
    "# 如出现“out of memory”的报错信息,可减小batch_size或resize\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
